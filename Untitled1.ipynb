{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataget import data\n",
    "import tfinterface as ti\n",
    "import sonnet as snt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cytoolz as cz\n",
    "from dicto import dicto\n",
    "import tensorrt as trt\n",
    "import uff\n",
    "from tensorrt.parsers import uffparser\n",
    "\n",
    "MAX_WORKSPACE = 1 << 20 # ADJUST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AllCNNN(snt.AbstractModule):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        kwargs[\"name\"] = kwargs.get(\"name\", \"AllCNN\")\n",
    "        super(AllCNNN, self).__init__(*args, **kwargs)\n",
    "    \n",
    "    def _build(self, inputs):\n",
    "        \n",
    "        print(\"##########################\")\n",
    "        print(\"## AllCNN\")\n",
    "        print(\"##########################\")\n",
    "        \n",
    "        net = inputs[\"image\"]; print(net)\n",
    "        training = inputs[\"mode\"] == tf.estimator.ModeKeys.TRAIN\n",
    "        \n",
    "        net = ti.layers.conv2d_batch_norm(net, 16, [4, 4], strides = 2, activation = tf.nn.relu, \n",
    "                                          padding = \"same\", batch_norm = dict(training = training)); print(net)\n",
    "        \n",
    "        \n",
    "        net = ti.layers.conv2d_batch_norm(net, 32, [4, 4], strides = 2, activation = tf.nn.relu, \n",
    "                                          padding = \"same\", batch_norm = dict(training = training)); print(net)\n",
    "        \n",
    "        \n",
    "        net = ti.layers.conv2d_batch_norm(net, 64, [3, 3], strides = 1, activation = tf.nn.relu, \n",
    "                                          padding = \"valid\", batch_norm = dict(training = training)); print(net)\n",
    "        \n",
    "        \n",
    "        net = tf.layers.conv2d(net, 10, [3, 3], strides = 1, activation = tf.nn.relu,\n",
    "                                          padding = \"valid\"); print(net)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # global average pooling\n",
    "        logits = net = tf.reduce_mean(net, axis = [1, 2]); print(net)\n",
    "        \n",
    "        # predictions\n",
    "        predictions = net = tf.nn.softmax(logits); print(net)\n",
    "    \n",
    "        print(\"\")\n",
    "        \n",
    "        return logits, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################\n",
      "## AllCNN\n",
      "##########################\n",
      "Tensor(\"input_layer_1:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "Tensor(\"AllCNN/Conv2dBatchNorm/Relu:0\", shape=(?, 14, 14, 16), dtype=float32)\n",
      "Tensor(\"AllCNN/Conv2dBatchNorm_1/Relu:0\", shape=(?, 7, 7, 32), dtype=float32)\n",
      "Tensor(\"AllCNN/Conv2dBatchNorm_2/Relu:0\", shape=(?, 5, 5, 64), dtype=float32)\n",
      "Tensor(\"AllCNN/conv2d/Relu:0\", shape=(?, 3, 3, 10), dtype=float32)\n",
      "Tensor(\"AllCNN/Mean:0\", shape=(?, 10), dtype=float32)\n",
      "Tensor(\"AllCNN/Softmax:0\", shape=(?, 10), dtype=float32)\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from models/all_cnn2/model.ckpt-503\n",
      "INFO:tensorflow:Froze 14 variables.\n",
      "Converted 14 variables to const ops.\n",
      "Using output node AllCNN/Softmax\n",
      "Converting to UFF graph\n",
      "No. nodes: 39\n"
     ]
    }
   ],
   "source": [
    "params = dicto.load_(\"parameters.yml\")\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default(), tf.Session(graph = graph) as sess:\n",
    "    \n",
    "    inputs = dict(\n",
    "        image = tf.layers.Input(shape=(28, 28, 1)),\n",
    "        mode = tf.estimator.ModeKeys.TRAIN,\n",
    "    )\n",
    "\n",
    "    all_cnn = AllCNNN()\n",
    "    logits, predictions = all_cnn(inputs)\n",
    "    \n",
    "    graph_def = graph.as_graph_def()\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    snapshot_fpath = tf.train.latest_checkpoint(params.model_dir)\n",
    "    saver.restore(sess, snapshot_fpath)\n",
    "    \n",
    "    # freeze graph and remove nodes used for training \n",
    "    frozen_graph = tf.graph_util.convert_variables_to_constants(sess, graph_def, params.OUTPUT_NAMES)\n",
    "    frozen_graph = tf.graph_util.remove_training_nodes(frozen_graph)\n",
    "    # Create UFF model and dump it on disk \n",
    "    uff_model = uff.from_tensorflow(frozen_graph, params.OUTPUT_NAMES)\n",
    "    dump = open('all_cnn.uff', 'wb')\n",
    "    dump.write(uff_model)\n",
    "    dump.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/cristian/anaconda2/lib/python2.7/site-packages/tensorrt/utils/_utils.py\", line 186, in uff_to_trt_engine\n",
      "    assert(parser_result)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "UFF parsing failed on line 186 in statement assert(parser_result)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a8d024a907e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m                                      \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# 1 sample at a time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                                      \u001b[0mmax_workspace_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m<<\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# 1 GB GPU memory workspace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                                      datatype=trt.infer.DataType.FLOAT) # that's very cool, you can set precision\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_execution_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cristian/anaconda2/lib/python2.7/site-packages/tensorrt/utils/_utils.pyc\u001b[0m in \u001b[0;36muff_to_trt_engine\u001b[0;34m(logger, stream, parser, max_batch_size, max_workspace_size, datatype, plugin_factory, calibrator)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'UFF parsing failed on line {} in statement {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: UFF parsing failed on line 186 in statement assert(parser_result)"
     ]
    }
   ],
   "source": [
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# This is a helper function, provided by TensorRT devs, to run inference\n",
    "def infer(context, input_img, batch_size):\n",
    "    \n",
    "    # load engine\n",
    "    engine = context.get_engine()\n",
    "    assert(engine.get_nb_bindings() == 2)\n",
    "    \n",
    "    # create output array to receive data\n",
    "    dims = engine.get_binding_dimensions(1).to_DimsCHW()\n",
    "    elt_count = dims.C() * dims.H() * dims.W() * batch_size\n",
    "    \n",
    "    # convert input data to Float32\n",
    "    input_img = input_img.astype(np.float32)\n",
    "    \n",
    "    # Allocate pagelocked memory\n",
    "    output = cuda.pagelocked_empty(elt_count, dtype=np.float32)\n",
    "    \n",
    "    # alocate device memory\n",
    "    d_input = cuda.mem_alloc(batch_size * input_img.size * input_img.dtype.itemsize)\n",
    "    d_output = cuda.mem_alloc(batch_size * output.size * output.dtype.itemsize)\n",
    "    bindings = [int(d_input), int(d_output)]\n",
    "    stream = cuda.Stream()\n",
    "    \n",
    "    # transfer input data to device\n",
    "    cuda.memcpy_htod_async(d_input, input_img, stream)\n",
    "    \n",
    "    # execute model\n",
    "    context.enqueue(batch_size, bindings, stream.handle, None)\n",
    "    \n",
    "    # transfer predictions back\n",
    "    cuda.memcpy_dtoh_async(output, d_output, stream)\n",
    "    \n",
    "    # return predictions\n",
    "    return output\n",
    "\n",
    "# load model\n",
    "uff_model = open('all_cnn.uff', 'rb').read()\n",
    "\n",
    "# create model parser\n",
    "parser = uffparser.create_uff_parser()\n",
    "\n",
    "for input in params.INPUTS:\n",
    "    parser.register_input(input.name, input.size, 0)\n",
    "\n",
    "for output in params.OUTPUT_NAMES:\n",
    "    parser.register_output(output)\n",
    "    \n",
    "# create inference engine and context (aka session)\n",
    "trt_logger = trt.infer.ConsoleLogger(trt.infer.LogSeverity.ERROR)\n",
    "engine = trt.utils.uff_to_trt_engine(logger=trt_logger,\n",
    "                                     stream=uff_model,\n",
    "                                     parser=parser,\n",
    "                                     max_batch_size=2, # 1 sample at a time\n",
    "                                     max_workspace_size= 1 << 30, # 1 GB GPU memory workspace\n",
    "                                     datatype=trt.infer.DataType.FLOAT) # that's very cool, you can set precision\n",
    "context = engine.create_execution_context()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
